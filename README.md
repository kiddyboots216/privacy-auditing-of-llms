# Privacy Auditing of Large Language Models

This repository contains the code implementation for the paper:

**[Privacy Auditing of LLMs](https://arxiv.org/abs/2503.06808)** (ICLR 2025)

## Overview

This project provides tools and scripts to perform privacy auditing on Large Language Models (LLMs) as described in the paper. The core idea involves training models on datasets containing specific "canary" sequences and then using Membership Inference Attacks (MIA) to assess whether the model has memorized these canaries, indicating potential privacy leaks.

## Prerequisites

Ensure you have the following dependencies installed:

*   Python 3.x
*   PyTorch
*   Transformers (Hugging Face)
*   scikit-learn

You can typically install these using pip:

```pip install torch transformers scikit-learn```

## Usage

1.  **Prepare Datasets:** The datasets used for training and evaluation, including the necessary canaries, are generated by `create_datasets.py`. If you need to modify or add new canaries, edit this script first. You don't need to run this, it will be ran automatically by the next step.
2.  **Run Training and Evaluation:** The main script `phish.py` handles the standard training of the LLM on the prepared dataset and subsequent evaluation. Execute the provided shell script to run the entire pipeline:
    ```bash
    bash run.sh
    ```
    This script will call `phish.py` with the appropriate arguments.

## File Descriptions

*   **`run.sh`**: Shell script to automate the execution of the training and evaluation pipeline.
*   **`create_datasets.py`**: Generates the training and evaluation datasets. This is where canary sequences are defined and inserted into the data.
*   **`phish.py`**: The main Python script that performs the LLM training and evaluation phases using the datasets generated by `create_datasets.py`.
*   **`audit_mia.py`**: Implements the privacy auditing method itself, with a specified confidence interval.

## Citation

If you use this code or methodology in your research, please cite our paper (published at ICLR 2025):

```bibtex
@misc{panda2025privacy,
  title        = {Privacy Auditing of LLMs},
  author       = {Ashwinee Panda and Xinyu Tang and Christopher Choquette Choo and Milad Nasr and Prateek Mittal},
  year         = {2025},
  eprint       = {2503.06808},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}
```